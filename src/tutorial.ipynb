{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7e8c87-a7a2-41bc-a013-a30f8fd16daa",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "Spark's Python wrapper lets us interact with data very similarly to Pandas, which should be very familiar to Python users. In this notebook you will learn how to use the basic functionality of the wrapper, as well as visualize the data that you will be working with for the project. Make sure you have downloaded and unzipped the data to the correct location before trying to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7de5d-9874-4311-b671-6fa09ba2b7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from pyspark.sql import SparkSession, dataframe\n",
    "import plotly.express as px\n",
    "geojson = px.data.gapminder()\n",
    "# create sparksession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"CS236\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeff980-1c7e-471e-b4fd-9ff2a852c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to write query plans to a file\n",
    "# you will be using this to understand how your queries are being processed\n",
    "def write_explain(df: dataframe.DataFrame, output_path: str = \"out.txt\"):\n",
    "    from contextlib import redirect_stdout\n",
    "    with open(output_path, \"w\") as f:\n",
    "        with redirect_stdout(f):\n",
    "            df.explain(extended=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8b15d-3dca-4f90-b635-c3af2eebc701",
   "metadata": {},
   "source": [
    "Read a csv to a Spark dataframe, then return the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b3171e-95dd-41d2-a216-3ef2399e1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sdf = spark.read.csv(\"../data/StateAndCountyData.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e36b5b-4598-4a1e-858d-3b97f3f46753",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = spark.read.csv(\"../data/StateAndCountyData.csv\", header=True)\n",
    "sdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f995d4f8-d7cb-43d6-a3d3-b216aa204eb2",
   "metadata": {},
   "source": [
    "Show the first 20 rows of the Spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd3b8a-0528-4514-bf53-c8727e5f4a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbdd528-0da9-40bd-97eb-d40649795d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.createOrReplaceTempView('state_county')\n",
    "# run your SQL query as you would with any database\n",
    "my_df = spark.sql(\n",
    "'''\n",
    "select \n",
    "  state\n",
    "  , avg(value) as avg\n",
    "from state_county\n",
    "where variable_code = 'PCT_LACCESS_POP15' \n",
    "group by state\n",
    "order by state\n",
    "'''\n",
    ")\n",
    "my_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bf510-8c6c-4b44-8242-f24b583d15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_explain(my_df)\n",
    "# print out the query plan\n",
    "my_df.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7b2fe-9844-4929-bbea-bfa5fd7af0aa",
   "metadata": {},
   "source": [
    "## Visualizing with Choropleths\n",
    "We will be using Plotly Express to easily visualize the data you will be working with. The most important arguments besides the dataframe itself are `locations` and `color`.\n",
    "- `locations` - the name of the column that defines which values go into which state in the chart\n",
    "- `color` - the name of the column that contains the values to be displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feaa4c7-5e22-48a7-813e-5fc7bffac512",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.choropleth(my_df,\n",
    "                    locations='state',\n",
    "                    color='avg',\n",
    "                    color_continuous_scale='spectral_r',\n",
    "                    locationmode='USA-states',\n",
    "                    scope='usa')\n",
    "fig.update_geos(\n",
    "    visible=True, \n",
    "    scope=\"usa\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba17ecf-a7b3-4bea-b8a0-e067fa4ed1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
